{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "hLO63Q9Au6mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re, string, requests\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import re, string, requests, joblib\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siK-zSCnuzbL",
        "outputId": "18e1c7d4-7a74-4cc9-b0f4-72cfdefba879"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Melakukan Preprocessing"
      ],
      "metadata": {
        "id": "1D_sHN-buvq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def get_slang_word_list(url):\n",
        "    response = requests.get(url)\n",
        "    slang_dict = {}\n",
        "    for line in response.text.splitlines():\n",
        "        if ':' in line:\n",
        "            key, value = line.split(':', 1)\n",
        "            slang_dict[key.strip()] = value.strip()\n",
        "    return slang_dict\n",
        "\n",
        "slang_url = 'https://raw.githubusercontent.com/lhquan244/SlangWord/main/SlangWord_2/SlangWordOriginal.txt'\n",
        "slangwords = get_slang_word_list(slang_url)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'): return wordnet.ADJ\n",
        "    elif tag.startswith('V'): return wordnet.VERB\n",
        "    elif tag.startswith('N'): return wordnet.NOUN\n",
        "    elif tag.startswith('R'): return wordnet.ADV\n",
        "    else: return wordnet.NOUN\n",
        "\n",
        "def processing_text(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
        "    text = re.sub(r'#[A-Za-z0-9_]+', '', text)\n",
        "    text = re.sub(r'RT[\\s]+', '', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.replace('\\n', ' ').strip().lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    cleaned_tokens = [\n",
        "        lemmatizer.lemmatize(slangwords.get(word, word), get_wordnet_pos(pos))\n",
        "        for word, pos in pos_tags\n",
        "        if word not in stop_words\n",
        "    ]\n",
        "    return ' '.join(cleaned_tokens)"
      ],
      "metadata": {
        "id": "QcIYIAYBy7uc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memuat Model"
      ],
      "metadata": {
        "id": "S5ynDvO9vGbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow model\n",
        "model_tf = tf.keras.models.load_model('tf_model.h5')\n",
        "tokenizer = joblib.load('tf_tokenizer.pkl')\n",
        "label_encoder_tf = joblib.load('tf_label_encoder.pkl')\n",
        "\n",
        "# Logistic Regression\n",
        "logreg_model = joblib.load('logreg_model.pkl')\n",
        "tfidf_logreg = joblib.load('tfidf_vectorizer.pkl')\n",
        "label_encoder_logreg = joblib.load('label_encoder.pkl')\n",
        "\n",
        "# SVM model\n",
        "svm_model = joblib.load('svm_model.pkl')\n",
        "tfidf_svm = joblib.load('svm_vectorizer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jISbuBwnvFWG",
        "outputId": "d6fba864-eb5f-448e-e849-768864de4f10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Data"
      ],
      "metadata": {
        "id": "0hjV6l4Dvcly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teks_baru = [\n",
        "    \"I love the clean interface and how easy it is to navigate the app.\",\n",
        "    \"It keeps freezing whenever I try to join a call. Super frustrating.\",\n",
        "    \"Everything works as expected, nothing special but no major issues either.\",\n",
        "    \"I regret installing it. Crashes every time I open it.\",\n",
        "    \"Audio quality is poor when using Bluetooth headsets.\",\n",
        "    \"I’ve just started using the app, so I can’t say much yet.\",\n",
        "    \"Just a regular app, not bad but not amazing either.\",\n",
        "]\n",
        "\n",
        "teks_baru_bersih = [processing_text(t) for t in teks_baru]"
      ],
      "metadata": {
        "id": "C6E-9hpcvfQP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference per-Model"
      ],
      "metadata": {
        "id": "vJugezeYvNkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow\n",
        "seqs_tf = tokenizer.texts_to_sequences(teks_baru_bersih)\n",
        "pad_tf = tf.keras.preprocessing.sequence.pad_sequences(seqs_tf, maxlen=100, padding='post')\n",
        "pred_tf = model_tf.predict(pad_tf)\n",
        "label_tf = label_encoder_tf.inverse_transform(np.argmax(pred_tf, axis=1))\n",
        "\n",
        "# Logistic Regression\n",
        "X_logreg = tfidf_logreg.transform(teks_baru_bersih)\n",
        "pred_logreg = logreg_model.predict(X_logreg)\n",
        "\n",
        "# SVM\n",
        "X_svm = tfidf_svm.transform(teks_baru_bersih)\n",
        "pred_svm = svm_model.predict(X_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wl1GySXvQ7c",
        "outputId": "25f1aa2b-bfba-40d8-e3b8-38affdaee1f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Result"
      ],
      "metadata": {
        "id": "qimDtRyYvkWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Inference Comparison ===\\n\")\n",
        "for i, teks in enumerate(teks_baru):\n",
        "    print(f\"Teks: {teks}\")\n",
        "    print(f\"=> TensorFlow: {label_tf[i]}\")\n",
        "    print(f\"=> Logistic Regression: {pred_logreg[i]}\")\n",
        "    print(f\"=> SVM: {pred_svm[i]}\")\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g9m3_llvnEu",
        "outputId": "0d084026-97a7-4c7e-9195-7fae829e08d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inference Comparison ===\n",
            "\n",
            "Teks: I love the clean interface and how easy it is to navigate the app.\n",
            "=> TensorFlow: positive\n",
            "=> Logistic Regression: positive\n",
            "=> SVM: positive\n",
            "------------------------------------------------------------\n",
            "Teks: It keeps freezing whenever I try to join a call. Super frustrating.\n",
            "=> TensorFlow: negative\n",
            "=> Logistic Regression: negative\n",
            "=> SVM: negative\n",
            "------------------------------------------------------------\n",
            "Teks: Everything works as expected, nothing special but no major issues either.\n",
            "=> TensorFlow: positive\n",
            "=> Logistic Regression: neutral\n",
            "=> SVM: positive\n",
            "------------------------------------------------------------\n",
            "Teks: I regret installing it. Crashes every time I open it.\n",
            "=> TensorFlow: negative\n",
            "=> Logistic Regression: negative\n",
            "=> SVM: negative\n",
            "------------------------------------------------------------\n",
            "Teks: Audio quality is poor when using Bluetooth headsets.\n",
            "=> TensorFlow: negative\n",
            "=> Logistic Regression: negative\n",
            "=> SVM: negative\n",
            "------------------------------------------------------------\n",
            "Teks: I’ve just started using the app, so I can’t say much yet.\n",
            "=> TensorFlow: neutral\n",
            "=> Logistic Regression: neutral\n",
            "=> SVM: neutral\n",
            "------------------------------------------------------------\n",
            "Teks: Just a regular app, not bad but not amazing either.\n",
            "=> TensorFlow: neutral\n",
            "=> Logistic Regression: negative\n",
            "=> SVM: negative\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari hasil perbandingan inference, ketiga model (TensorFlow, Logistic Regression, dan SVM) menunjukkan performa yang stabil pada teks yang sangat positif atau negatif. Namun, pada teks yang bernuansa netral atau ambigu, perbedaan pendekatan dalam memahami konteks antar model menyebabkan variasi hasil klasifikasi."
      ],
      "metadata": {
        "id": "BuDNvyL70iKo"
      }
    }
  ]
}